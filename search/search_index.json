{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome Welcome to the Connext docs! At Connext, our goal is to build the cross-chain routing and micropayment layer of the decentralized web. Connext sits on top of Ethereum, evm-compatible L2 blockchains, and other turing-complete chains, and enables instant, near free transfers that can be routed across chains and over liquidity in any asset . Most importantly, it does this without giving up the trust-minimization properties of the underlying chain. You can think of Connext as a shared standard for blockchains and other decentralized networks to communicate with each other about value. Where Do I Start? If you're building a browser dApp, check out the browser-node quick start guide. If you're building a p2p network that uses programmable micropayments, you likely want to run a router If you're building a p2p network on top of Connext, you likely want a combination of node and router docs. etc. If you're still confused about where to begin, join us in our community chat! We're very responsive and happy to point you to the right resources. :)","title":"Welcome"},{"location":"#welcome","text":"Welcome to the Connext docs! At Connext, our goal is to build the cross-chain routing and micropayment layer of the decentralized web. Connext sits on top of Ethereum, evm-compatible L2 blockchains, and other turing-complete chains, and enables instant, near free transfers that can be routed across chains and over liquidity in any asset . Most importantly, it does this without giving up the trust-minimization properties of the underlying chain. You can think of Connext as a shared standard for blockchains and other decentralized networks to communicate with each other about value.","title":"Welcome"},{"location":"#where-do-i-start","text":"If you're building a browser dApp, check out the browser-node quick start guide. If you're building a p2p network that uses programmable micropayments, you likely want to run a router If you're building a p2p network on top of Connext, you likely want a combination of node and router docs. etc. If you're still confused about where to begin, join us in our community chat! We're very responsive and happy to point you to the right resources. :)","title":"Where Do I Start?"},{"location":"node/basics/","text":"Basics A Connext node is an implementation of the Connext protocols. Anyone who is using Connext in any way should most likely be running a node. Nodes take in the following: - Access to a user key, from which a ChannelSigner can be created. - etc. There are two primary node implementations available right now, both written in Typescript: - server-node - browser-node Server-Node vs. Browser-Node In general, nodes expose very similar interfaces and behave very similarly. There are a few notable differences, however: Server-Node Browser-Node Interface(s) gRPC and REST typescript Distribution Docker image npm Environment Variables Passed in via config-node.json file Set via .env or passed in on instantiation Key Management Takes in a mnemonic and supports creating multiple signers by passing in an index . See more below. Takes in a single ChannelSigner Server-Node Specific Functionality Using the Server Node JS Client The server-node's HTTP requests are wrapped into a JS client . This can be installed into a standalone Node.js program by installing the @connext/vector-utils package. Minimally, the client is instantiated like so (assuming a local setup similar to make start-node or make start-duet ): import { RestServerNodeService } from \"@connext/vector-utils\" ; import pino from \"pino\" ; const alice = await RestServerNodeService . connect ( \"http://localhost:8001\" , { 1337 : \"http://localhost:8545\" }, pino ()); The client has wrapper methods for the server-node 's REST interface, which implement the interface IServerNodeService . Note: because the browser-node exposes a TS interface directly, there is no need to do this in the browser. Indexed Engines In most cases, the server-node manages a single private key and signs all channel operations with this key. However, server-nodes also possess the ability to handle many different signers in the same stack concurrently. You can do this by specifying an index param in the connect method. This functionality is possible in the server-node by deriving private keys from the mnemonic in the server-node 's config ( more info ). By default, the server-node creates an engine at the index path \"0\" for convenience. Below is an example of creating a new Engine instance. The index param is an integer between 0 and 2147483647 (2^32): POST {{aliceUrl}}/node Content-Type: application/json { \"index\": 1234 } The response to this request contains a signerAddress and publicIdentifier . Additional calls to the server node must include the publicIdentifier to specify which engine to use.","title":"Basics"},{"location":"node/basics/#basics","text":"A Connext node is an implementation of the Connext protocols. Anyone who is using Connext in any way should most likely be running a node. Nodes take in the following: - Access to a user key, from which a ChannelSigner can be created. - etc. There are two primary node implementations available right now, both written in Typescript: - server-node - browser-node","title":"Basics"},{"location":"node/basics/#server-node-vs-browser-node","text":"In general, nodes expose very similar interfaces and behave very similarly. There are a few notable differences, however: Server-Node Browser-Node Interface(s) gRPC and REST typescript Distribution Docker image npm Environment Variables Passed in via config-node.json file Set via .env or passed in on instantiation Key Management Takes in a mnemonic and supports creating multiple signers by passing in an index . See more below. Takes in a single ChannelSigner","title":"Server-Node vs. Browser-Node"},{"location":"node/basics/#server-node-specific-functionality","text":"","title":"Server-Node Specific Functionality"},{"location":"node/basics/#using-the-server-node-js-client","text":"The server-node's HTTP requests are wrapped into a JS client . This can be installed into a standalone Node.js program by installing the @connext/vector-utils package. Minimally, the client is instantiated like so (assuming a local setup similar to make start-node or make start-duet ): import { RestServerNodeService } from \"@connext/vector-utils\" ; import pino from \"pino\" ; const alice = await RestServerNodeService . connect ( \"http://localhost:8001\" , { 1337 : \"http://localhost:8545\" }, pino ()); The client has wrapper methods for the server-node 's REST interface, which implement the interface IServerNodeService . Note: because the browser-node exposes a TS interface directly, there is no need to do this in the browser.","title":"Using the Server Node JS Client"},{"location":"node/basics/#indexed-engines","text":"In most cases, the server-node manages a single private key and signs all channel operations with this key. However, server-nodes also possess the ability to handle many different signers in the same stack concurrently. You can do this by specifying an index param in the connect method. This functionality is possible in the server-node by deriving private keys from the mnemonic in the server-node 's config ( more info ). By default, the server-node creates an engine at the index path \"0\" for convenience. Below is an example of creating a new Engine instance. The index param is an integer between 0 and 2147483647 (2^32): POST {{aliceUrl}}/node Content-Type: application/json { \"index\": 1234 } The response to this request contains a signerAddress and publicIdentifier . Additional calls to the server node must include the publicIdentifier to specify which engine to use.","title":"Indexed Engines"},{"location":"node/configure/","text":"Configuration and Deployment The node stack is configurable via the config-node.json file. Note that the duet and trio stacks are designed exclusively for development/testing so these are not configurable. There is an additional config-prod.json file that can apply to either the node or router but not both. The config-prod.json file contains your domain name and, because it's not tracked by git, it's a good place to put overrides for secret values like API keys. A prod-mode deployment using a domain name w https must be exposed on port 443, therefore only a single prod-mode stack can run on a given machine at a time. Node Configuration API config-node.json contains the default configuration for the node stack: make start-node . Any of these values can be overwritten by providing the same key with a new value to config-prod.json . Node Config Keys: adminToken (type: string ): Currently, this is only used during development to protect a few admin endpoints eg to reset the database between tests. If/when we add admin-only features in prod, they will only be accessible to those who provide the correct adminToken. chainAddresses (type: object ): Specifies the addresses of all relevant contracts, keyed by chainId . chainProviders (type: object ): Specifies the URL to use to connect to each chain's provider, keyed by chainId logLevel (type: string ): one of \"debug\" , \"info\" , \"warn\" , \"error\" to specify the maximum log level that will be printed. messagingUrl (type: string ): The url used to access the messaging service mnemonic (type: string ): Optional. If provided, the node will use this mnemonic. If not provided, the node will use a hard coded mnemonic with testnet funds in dev-mode (production=false). If not provided in prod, docker secrets will be used to manage the mnemonic; this is a much safer place to store a mnemonic that eg holds mainnet funds. port (type: number ): The port number on which the stack should be exposed to the outside world. redisUrl (type: string ): The URL of the redis instance used to negotiate channel-locks. Prod Configuration API Changes to config-prod.json aren't tracked by git so this is a good place to store secret API keys, etc. Be careful, changes to this file will be applied to both node & router stacks running on this machine. Prod Config Keys: awsAccessId (type: string ): An API KEY id that specifies credentials for a remote AWS S3 bucket for storing db backups awsAccessKey (type: string ): An API KEY secret that to authenticate on a remote AWS S3 bucket for storing db backups. domainName (type: string ): If provided, https will be auto-configured & the stack will be exposed on port 443. production (type: boolean ): Enables prod-mode if true. Implications of this flag: if false , ops will automatically build anything that isn't available locally before starting up a given stack. If true , nothing will be built locally. Instead, all images will be pulled from docker hub. if false , the global stack will start up 2 local testnet evm. Mnemonic handling is affected, see docs for the mnemonic key in node config. Example Configurations Basic Multiple Chains","title":"Configuration and Deployment"},{"location":"node/configure/#configuration-and-deployment","text":"The node stack is configurable via the config-node.json file. Note that the duet and trio stacks are designed exclusively for development/testing so these are not configurable. There is an additional config-prod.json file that can apply to either the node or router but not both. The config-prod.json file contains your domain name and, because it's not tracked by git, it's a good place to put overrides for secret values like API keys. A prod-mode deployment using a domain name w https must be exposed on port 443, therefore only a single prod-mode stack can run on a given machine at a time.","title":"Configuration and Deployment"},{"location":"node/configure/#node-configuration-api","text":"config-node.json contains the default configuration for the node stack: make start-node . Any of these values can be overwritten by providing the same key with a new value to config-prod.json . Node Config Keys: adminToken (type: string ): Currently, this is only used during development to protect a few admin endpoints eg to reset the database between tests. If/when we add admin-only features in prod, they will only be accessible to those who provide the correct adminToken. chainAddresses (type: object ): Specifies the addresses of all relevant contracts, keyed by chainId . chainProviders (type: object ): Specifies the URL to use to connect to each chain's provider, keyed by chainId logLevel (type: string ): one of \"debug\" , \"info\" , \"warn\" , \"error\" to specify the maximum log level that will be printed. messagingUrl (type: string ): The url used to access the messaging service mnemonic (type: string ): Optional. If provided, the node will use this mnemonic. If not provided, the node will use a hard coded mnemonic with testnet funds in dev-mode (production=false). If not provided in prod, docker secrets will be used to manage the mnemonic; this is a much safer place to store a mnemonic that eg holds mainnet funds. port (type: number ): The port number on which the stack should be exposed to the outside world. redisUrl (type: string ): The URL of the redis instance used to negotiate channel-locks.","title":"Node Configuration API"},{"location":"node/configure/#prod-configuration-api","text":"Changes to config-prod.json aren't tracked by git so this is a good place to store secret API keys, etc. Be careful, changes to this file will be applied to both node & router stacks running on this machine. Prod Config Keys: awsAccessId (type: string ): An API KEY id that specifies credentials for a remote AWS S3 bucket for storing db backups awsAccessKey (type: string ): An API KEY secret that to authenticate on a remote AWS S3 bucket for storing db backups. domainName (type: string ): If provided, https will be auto-configured & the stack will be exposed on port 443. production (type: boolean ): Enables prod-mode if true. Implications of this flag: if false , ops will automatically build anything that isn't available locally before starting up a given stack. If true , nothing will be built locally. Instead, all images will be pulled from docker hub. if false , the global stack will start up 2 local testnet evm. Mnemonic handling is affected, see docs for the mnemonic key in node config.","title":"Prod Configuration API"},{"location":"node/configure/#example-configurations","text":"","title":"Example Configurations"},{"location":"node/configure/#basic","text":"","title":"Basic"},{"location":"node/configure/#multiple-chains","text":"","title":"Multiple Chains"},{"location":"node/events/","text":"Events To subscribe to the server-node 's event emitter, the JS client uses webhooks. A program that wants to listen for the server-node 's events needs to implement an HTTP server that can accept POST requests which the server-node POSTs to when events are generated. The JS client uses a mapping of EVTs which should be posted to when the HTTP request is received to allow for more powerful filtering capabilities behind an easy to use interface. A full example can be found in the implementation of the router module , here are relevant snippets: import { Evt } from \"evt\" ; import fastify from \"fastify\" ; import { RestServerNodeService } from \"@connext/vector-utils\" ; import { ConditionalTransferCreatedPayload , ConditionalTransferResolvedPayload , EngineEvents , } from \"@connext/vector-types\" ; // using fastify as the web server const server = fastify (); // configure event subscriptions const serverBase = `http://localhost:3000` ; // this server // callback paths const conditionalTransferCreatedPath = \"/conditional-transfer-created\" ; const conditionalTransferResolvedPath = \"/conditional-transfer-resolved\" ; const evts = { [ EngineEvents . CONDITIONAL_TRANSFER_CREATED ] : { evt : Evt.create < ConditionalTransferCreatedPayload > (), url : ` ${ routerBase }${ conditionalTransferCreatedPath } ` , }, [ EngineEvents . CONDITIONAL_TRANSFER_RESOLVED ] : { evt : Evt.create < ConditionalTransferResolvedPayload > (), url : ` ${ routerBase }${ conditionalTransferResolvedPath } ` , }, [ EngineEvents . SETUP ] : {}, [ EngineEvents . WITHDRAWAL_CREATED ] : {}, [ EngineEvents . WITHDRAWAL_RESOLVED ] : {}, [ EngineEvents . WITHDRAWAL_RECONCILED ] : {}, [ EngineEvents . DEPOSIT_RECONCILED ] : {}, }; const logger = pino (); let node : RestServerNodeService | undefined ; server . addHook ( \"onReady\" , async () => { // asynchronously connect to server node node = await RestServerNodeService . connect ( \"http://localhost:8001\" , { 1337 : \"http://localhost:8545\" }, logger . child ({ module : \"RestServerNodeService\" }), // namespace logs by module evts , // event subscription config ); }); // endpoints to receive server-node events server . post ( conditionalTransferCreatedPath , async ( request , response ) => { // post to the EVT that we pass into the server-node client evts [ EngineEvents . CONDITIONAL_TRANSFER_CREATED ]. post ( request . body as ConditionalTransferCreatedPayload ); return response . status ( 200 ). send ({ message : \"success\" }); }); server . post ( conditionalTransferResolvedPath , async ( request , response ) => { evts [ EngineEvents . CONDITIONAL_TRANSFER_RESOLVED ]. post ( request . body as ConditionalTransferResolvedPayload ); return response . status ( 200 ). send ({ message : \"success\" }); }); await node . on ( EngineEvents . CONDITIONAL_TRANSFER_CREATED , async data => { console . log ( `Received conditional transfer: ${ JSON . stringify ( data ) } ` ); }, data => data . transfer . initiator === \"indraABCD\" , // can filter on the data here );","title":"Events"},{"location":"node/events/#events","text":"To subscribe to the server-node 's event emitter, the JS client uses webhooks. A program that wants to listen for the server-node 's events needs to implement an HTTP server that can accept POST requests which the server-node POSTs to when events are generated. The JS client uses a mapping of EVTs which should be posted to when the HTTP request is received to allow for more powerful filtering capabilities behind an easy to use interface. A full example can be found in the implementation of the router module , here are relevant snippets: import { Evt } from \"evt\" ; import fastify from \"fastify\" ; import { RestServerNodeService } from \"@connext/vector-utils\" ; import { ConditionalTransferCreatedPayload , ConditionalTransferResolvedPayload , EngineEvents , } from \"@connext/vector-types\" ; // using fastify as the web server const server = fastify (); // configure event subscriptions const serverBase = `http://localhost:3000` ; // this server // callback paths const conditionalTransferCreatedPath = \"/conditional-transfer-created\" ; const conditionalTransferResolvedPath = \"/conditional-transfer-resolved\" ; const evts = { [ EngineEvents . CONDITIONAL_TRANSFER_CREATED ] : { evt : Evt.create < ConditionalTransferCreatedPayload > (), url : ` ${ routerBase }${ conditionalTransferCreatedPath } ` , }, [ EngineEvents . CONDITIONAL_TRANSFER_RESOLVED ] : { evt : Evt.create < ConditionalTransferResolvedPayload > (), url : ` ${ routerBase }${ conditionalTransferResolvedPath } ` , }, [ EngineEvents . SETUP ] : {}, [ EngineEvents . WITHDRAWAL_CREATED ] : {}, [ EngineEvents . WITHDRAWAL_RESOLVED ] : {}, [ EngineEvents . WITHDRAWAL_RECONCILED ] : {}, [ EngineEvents . DEPOSIT_RECONCILED ] : {}, }; const logger = pino (); let node : RestServerNodeService | undefined ; server . addHook ( \"onReady\" , async () => { // asynchronously connect to server node node = await RestServerNodeService . connect ( \"http://localhost:8001\" , { 1337 : \"http://localhost:8545\" }, logger . child ({ module : \"RestServerNodeService\" }), // namespace logs by module evts , // event subscription config ); }); // endpoints to receive server-node events server . post ( conditionalTransferCreatedPath , async ( request , response ) => { // post to the EVT that we pass into the server-node client evts [ EngineEvents . CONDITIONAL_TRANSFER_CREATED ]. post ( request . body as ConditionalTransferCreatedPayload ); return response . status ( 200 ). send ({ message : \"success\" }); }); server . post ( conditionalTransferResolvedPath , async ( request , response ) => { evts [ EngineEvents . CONDITIONAL_TRANSFER_RESOLVED ]. post ( request . body as ConditionalTransferResolvedPayload ); return response . status ( 200 ). send ({ message : \"success\" }); }); await node . on ( EngineEvents . CONDITIONAL_TRANSFER_CREATED , async data => { console . log ( `Received conditional transfer: ${ JSON . stringify ( data ) } ` ); }, data => data . transfer . initiator === \"indraABCD\" , // can filter on the data here );","title":"Events"},{"location":"quickStart/browserNode/","text":"Browser Node Quick Start This quick start will guide you through getting to a simple e2e transfer flow running between two peers running browser nodes that runs through an intermediary routing node. We assume you're starting with an existing JS application that runs in the browser. Spinning Up a Router Locally Prerequisites: make : Probably already installed, otherwise install w brew install make or apt install make or similar. jq : Probably not installed yet, install w brew install jq or apt install jq or similar. docker : sadly, Docker is kinda annoying to install. See website for instructions. First, clone the repo: git clone git@github.com:connext/vector.git cd vector Then, run: make start-router The above command will spin up a routing node in dev-mode along with some local services for messaging and auth. It will also create two local blockchains (at chainIds 1337 and 1338 respectively) and then will deploy the Connext contracts to those chains. Installation and Instantiation You can install the browser-node via npm : npm i @connext/vector-browser-node --save You'll also probably want the vector-utils package. npm i @connext/vector-utils --save Instantiating the node takes in the following constructor params: chainProviders : A provider URL for whatever chain(s) you want to connect to. E.g. Infura, Geth node in VPC, etc. Indexed by chainId . chainAddresses : An object containing Connext contract addresses also indexed by chainId . signer : A ChannelSigner, which can be created using the vector-utils package and a private key. messagingUrl : Local or remote URL access to a messaging service. In prod-mode, this is automatically defaulted to a global service. logger : A pino logger.","title":"Browser Node Quick Start"},{"location":"quickStart/browserNode/#browser-node-quick-start","text":"This quick start will guide you through getting to a simple e2e transfer flow running between two peers running browser nodes that runs through an intermediary routing node. We assume you're starting with an existing JS application that runs in the browser.","title":"Browser Node Quick Start"},{"location":"quickStart/browserNode/#spinning-up-a-router-locally","text":"Prerequisites: make : Probably already installed, otherwise install w brew install make or apt install make or similar. jq : Probably not installed yet, install w brew install jq or apt install jq or similar. docker : sadly, Docker is kinda annoying to install. See website for instructions. First, clone the repo: git clone git@github.com:connext/vector.git cd vector Then, run: make start-router The above command will spin up a routing node in dev-mode along with some local services for messaging and auth. It will also create two local blockchains (at chainIds 1337 and 1338 respectively) and then will deploy the Connext contracts to those chains.","title":"Spinning Up a Router Locally"},{"location":"quickStart/browserNode/#installation-and-instantiation","text":"You can install the browser-node via npm : npm i @connext/vector-browser-node --save You'll also probably want the vector-utils package. npm i @connext/vector-utils --save Instantiating the node takes in the following constructor params: chainProviders : A provider URL for whatever chain(s) you want to connect to. E.g. Infura, Geth node in VPC, etc. Indexed by chainId . chainAddresses : An object containing Connext contract addresses also indexed by chainId . signer : A ChannelSigner, which can be created using the vector-utils package and a private key. messagingUrl : Local or remote URL access to a messaging service. In prod-mode, this is automatically defaulted to a global service. logger : A pino logger.","title":"Installation and Instantiation"},{"location":"quickStart/serverNode/","text":"Server Node Quick Start This quick start will guide you through getting to a simple e2e transfer flow between two peers running server-nodes (Carol, Dave) that is routed through one intermediary routing node (Roger). Spinning Up the Stack Locally Prerequisites: make : Probably already installed, otherwise install w brew install make or apt install make or similar. jq : Probably not installed yet, install w brew install jq or apt install jq or similar. docker : sadly, Docker is kinda annoying to install. See website for instructions. First, clone the repo: git clone git@github.com:connext/vector.git cd vector Then, run: make start-trio The above command will spin up three server-nodes, one with an attached router in dev-mode. Note that in dev-mode, chain and db data will not be persisted between restarts. To run in prod mode, you can spin up a routing node with make start-router and non-routing server-nodes with make start-node . We have a guide on prod-mode deployments and configuration coming soon! Creating a Channel Once you have the above trio set up, you can interact with your nodes via a REST interface. We've documented example requests in the server-node module. If you're developing with VSCode, there are several REST client plugins available in the marketplace that you can use to make these queries directly from the examples . First, set up your nodes (in 0_config ) on the servers to register signers and create the engines. ### Node -> Carol POST {{carolUrl}}/node Content-Type: application/json { \"index\": 0 } ### Node -> Dave POST {{daveUrl}}/node Content-Type: application/json { \"index\": 0 } Then, set up your channels from Carol -> Roger and Roger -> Carol (in 1_Setup ). Note aliceUrl is the internal URL that Carol has access to on the Docker network. In these examples, Carol and Dave are requesting Roger to set up the channel with them so that they can be the \"Bob\" within the channel, which lets them deposit by transferrring directly into the channel address.: ### Node -> Carol POST {{carolUrl}}/request-setup Content-Type: application/json { \"aliceUrl\": \"http://roger:8000\", \"chainId\": \"{{chainId}}\", \"timeout\": \"36000\", \"publicIdentifier\": \"{{carolIdentifier}}\" } ### Node -> Dave POST {{daveUrl}}/request-setup Content-Type: application/json { \"aliceUrl\": \"http://roger:8000\", \"chainId\": \"{{chainId}}\", \"timeout\": \"36000\", \"publicIdentifier\": \"{{daveIdentifier}}\" } Depositing Into a Channel Then, send an Eth deposit to Carol's channel onchain. This can be done by connecting Metamask to your local EVM at http://localhost:8545 and sending a transfer directly to the channelAddress , at any time, regardless of either channel participant's liveness status. A convenient way to do this using HTTP JSON-RPC calls is with a POST request: # Send a transaction to {{channelAddress}} for 100000000000000000 Wei POST http://localhost:8545 Content-Type: application/json { \"jsonrpc\":\"2.0\", \"method\":\"eth_sendTransaction\", \"params\":[{ \"from\": \"0x627306090abaB3A6e1400e9345bC60c78a8BEf57\", \"to\": \"{{channelAddress}}\", \"value\": \"0x16345785d8a0000\", \"data\": \"0x0\" }], \"id\":1 } To add this to Carol's offchain balance, you need to wait for the tx to be mined and then call: POST {{carolUrl}}/deposit Content-Type: application/json { \"channelAddress\": \"{{carolNodeChannel}}\", \"assetId\": \"0x0000000000000000000000000000000000000000\", \"publicIdentifier\": \"{{carolIdentifier}}\" } Making a Transfer Then, create a transfer between Carol and Dave through Roger (in 3_transfer ): POST {{carolUrl}}/hashlock-transfer/create Content-Type: application/json { \"conditionType\": \"HashlockTransfer\", \"channelAddress\": \"{{carolNodeChannel}}\", \"amount\": \"{{ethAmount}}\", \"assetId\": \"0x0000000000000000000000000000000000000000\", \"details\": { \"lockHash\": \"{{lockHash}}\" }, \"routingId\": \"{{routingId}}\", \"recipient\": \"{{davePublicIdentifier}}\", \"meta\": { \"hello\": \"world\" }, \"publicIdentifier\": \"{{carolIdentifier}}\" } Lastly, unlock the transfer for Bob to get his funds: POST {{daveUrl}}/hashlock-transfer/resolve Content-Type: application/json { \"channelAddress\": \"{{daveNodeChannel}}\", \"routingId\": \"{{routingId}}\", \"preImage\": \"{{preImage}}\", \"publicIdentifier\": \"{{daveIdentifier}}\" }","title":"Server Node Quick Start"},{"location":"quickStart/serverNode/#server-node-quick-start","text":"This quick start will guide you through getting to a simple e2e transfer flow between two peers running server-nodes (Carol, Dave) that is routed through one intermediary routing node (Roger).","title":"Server Node Quick Start"},{"location":"quickStart/serverNode/#spinning-up-the-stack-locally","text":"Prerequisites: make : Probably already installed, otherwise install w brew install make or apt install make or similar. jq : Probably not installed yet, install w brew install jq or apt install jq or similar. docker : sadly, Docker is kinda annoying to install. See website for instructions. First, clone the repo: git clone git@github.com:connext/vector.git cd vector Then, run: make start-trio The above command will spin up three server-nodes, one with an attached router in dev-mode. Note that in dev-mode, chain and db data will not be persisted between restarts. To run in prod mode, you can spin up a routing node with make start-router and non-routing server-nodes with make start-node . We have a guide on prod-mode deployments and configuration coming soon!","title":"Spinning Up the Stack Locally"},{"location":"quickStart/serverNode/#creating-a-channel","text":"Once you have the above trio set up, you can interact with your nodes via a REST interface. We've documented example requests in the server-node module. If you're developing with VSCode, there are several REST client plugins available in the marketplace that you can use to make these queries directly from the examples . First, set up your nodes (in 0_config ) on the servers to register signers and create the engines. ### Node -> Carol POST {{carolUrl}}/node Content-Type: application/json { \"index\": 0 } ### Node -> Dave POST {{daveUrl}}/node Content-Type: application/json { \"index\": 0 } Then, set up your channels from Carol -> Roger and Roger -> Carol (in 1_Setup ). Note aliceUrl is the internal URL that Carol has access to on the Docker network. In these examples, Carol and Dave are requesting Roger to set up the channel with them so that they can be the \"Bob\" within the channel, which lets them deposit by transferrring directly into the channel address.: ### Node -> Carol POST {{carolUrl}}/request-setup Content-Type: application/json { \"aliceUrl\": \"http://roger:8000\", \"chainId\": \"{{chainId}}\", \"timeout\": \"36000\", \"publicIdentifier\": \"{{carolIdentifier}}\" } ### Node -> Dave POST {{daveUrl}}/request-setup Content-Type: application/json { \"aliceUrl\": \"http://roger:8000\", \"chainId\": \"{{chainId}}\", \"timeout\": \"36000\", \"publicIdentifier\": \"{{daveIdentifier}}\" }","title":"Creating a Channel"},{"location":"quickStart/serverNode/#depositing-into-a-channel","text":"Then, send an Eth deposit to Carol's channel onchain. This can be done by connecting Metamask to your local EVM at http://localhost:8545 and sending a transfer directly to the channelAddress , at any time, regardless of either channel participant's liveness status. A convenient way to do this using HTTP JSON-RPC calls is with a POST request: # Send a transaction to {{channelAddress}} for 100000000000000000 Wei POST http://localhost:8545 Content-Type: application/json { \"jsonrpc\":\"2.0\", \"method\":\"eth_sendTransaction\", \"params\":[{ \"from\": \"0x627306090abaB3A6e1400e9345bC60c78a8BEf57\", \"to\": \"{{channelAddress}}\", \"value\": \"0x16345785d8a0000\", \"data\": \"0x0\" }], \"id\":1 } To add this to Carol's offchain balance, you need to wait for the tx to be mined and then call: POST {{carolUrl}}/deposit Content-Type: application/json { \"channelAddress\": \"{{carolNodeChannel}}\", \"assetId\": \"0x0000000000000000000000000000000000000000\", \"publicIdentifier\": \"{{carolIdentifier}}\" }","title":"Depositing Into a Channel"},{"location":"quickStart/serverNode/#making-a-transfer","text":"Then, create a transfer between Carol and Dave through Roger (in 3_transfer ): POST {{carolUrl}}/hashlock-transfer/create Content-Type: application/json { \"conditionType\": \"HashlockTransfer\", \"channelAddress\": \"{{carolNodeChannel}}\", \"amount\": \"{{ethAmount}}\", \"assetId\": \"0x0000000000000000000000000000000000000000\", \"details\": { \"lockHash\": \"{{lockHash}}\" }, \"routingId\": \"{{routingId}}\", \"recipient\": \"{{davePublicIdentifier}}\", \"meta\": { \"hello\": \"world\" }, \"publicIdentifier\": \"{{carolIdentifier}}\" } Lastly, unlock the transfer for Bob to get his funds: POST {{daveUrl}}/hashlock-transfer/resolve Content-Type: application/json { \"channelAddress\": \"{{daveNodeChannel}}\", \"routingId\": \"{{routingId}}\", \"preImage\": \"{{preImage}}\", \"publicIdentifier\": \"{{daveIdentifier}}\" }","title":"Making a Transfer"},{"location":"router/basics/","text":"Basics Router is an automated module that allows a server-node to act as an intermediary in hopped transactions between different peers in a network. For now, nodes that have the router enabled, i.e. routing nodes can only forward transfers to non-routing peers. Eventually, this routing module can be expanded to allow routing nodes to route value to other routing nodes, thereby creating a fully-decentralized state channel network. Responsibilities Router consumes the server-node gRPC interface to do the following: Listen to incoming events from the node for inbound transfers. Parse the transfer metadata to find routing information (recipient, chainId, assetId, requireOnline, etc.). Look up the recipient's channel using the above info. Check that the recipient's channel has enough collateral. If not, send a deposit to collateralize the channel and wait for it to be completed. As part of resolving transfers, the router will also reclaim collateral from channels. Dispatch the transfer. If the transfer fails and the transfer requires that the recipient is online, then hard error and cancel the sender side transfer too. Else, store the transfer and wait for the recipient to come back online. When a recipient comes online, the node emits an isAlive event for that channel. Router should catch isAlive events and complete all pending transfers to the recipient. Note that validation around allowed transfer types all happens in the node itself.","title":"Basics"},{"location":"router/basics/#basics","text":"Router is an automated module that allows a server-node to act as an intermediary in hopped transactions between different peers in a network. For now, nodes that have the router enabled, i.e. routing nodes can only forward transfers to non-routing peers. Eventually, this routing module can be expanded to allow routing nodes to route value to other routing nodes, thereby creating a fully-decentralized state channel network.","title":"Basics"},{"location":"router/basics/#responsibilities","text":"Router consumes the server-node gRPC interface to do the following: Listen to incoming events from the node for inbound transfers. Parse the transfer metadata to find routing information (recipient, chainId, assetId, requireOnline, etc.). Look up the recipient's channel using the above info. Check that the recipient's channel has enough collateral. If not, send a deposit to collateralize the channel and wait for it to be completed. As part of resolving transfers, the router will also reclaim collateral from channels. Dispatch the transfer. If the transfer fails and the transfer requires that the recipient is online, then hard error and cancel the sender side transfer too. Else, store the transfer and wait for the recipient to come back online. When a recipient comes online, the node emits an isAlive event for that channel. Router should catch isAlive events and complete all pending transfers to the recipient. Note that validation around allowed transfer types all happens in the node itself.","title":"Responsibilities"},{"location":"router/configure/","text":"Configuration and Deployment This guide will take you through the e2e process of configuring and deploying a router. First get started by cloning the repo if you haven't already git clone git@github.com:connext/vector.git Contract Deployment Before anything else, you should first ensure that the required Vector contracts are deployed to your chain. We have a global address-book in the root of the Vector repo which contains deployed contract addresses indexed by chainId. If you can't find the specific chain(s) that you want to set up a router at, you likely first need to deploy contracts. To deploy contracts, you can use our contracts CLI tool! First, build the repo: # in vector root make This should take a few moments. After it's done, cd into the contract repo and call the CLI migrate command: cd modules/contracts dist/cli.js migrate --address-book = /data/address-book.json --mnemonic = $mnemonic --ethProvider = $ethProvider Where $mnemonic controls a funded account on whatever chain you plan to deploy to, and $ethProvider is a provider URL for the same chain (e.g. Infura). Setting Up Required Dependencies In this section, we assume that you are trying to deploy your router to a remote Ubuntu-based instance. If you're spinning up the router locally, or are using an instance on a different operating system, you'll need to install the following dependencies yourself: make : Probably already installed, otherwise install w brew install make or apt install make or similar. jq : Probably not installed yet, install w brew install jq or apt install jq or similar. docker : sadly, Docker is kinda annoying to install. See website for instructions. To set up dependencies for a remote Ubuntu-based instance, we will use the server-setup.sh script located in the ops/ dir. First, make sure that you've set up your instance and have the instance's IP/URL on hand + ssh access. Then, clone the repo locally if you haven't already: git clone git@github.com:connext/vector.git Info The prod configuration of the router will eventually include a built-in proxy that will automatically set up a DNS and SSL certificates for you. For now, we recommend directly connecting to an exposed instance without setting up a domain name until that's ready. Next, run bash ops/server-setup.sh passing in the instance's IP address or URL. The script will look for your AWS SSH key at -$HOME/.ssh/id_rsa . If your ssh key is located elsewhere, be sure to amend the server-setup.sh script to direct to your actual keyfile, or else it will fail to log in. When the script runs, it will prompt you to pass in a mnemonic. Generate a random mnemonic from here , copy it to your clipboard, and paste it into the prompt. If you choose not to enter a mnemonic, the router will use a default hardcoded mnemonic. Be sure to back up your mnemonic somewhere safe! Your mnemonic generates the primary key that controls the router. Warning We strongly recommend that you do not use the hardcoded mnemonic for any router that is connected to a public chain, including a testnet. The hardcoded mnemonic is publicly viewable in our repo and using it, even just for testing, could result in unpredictable behavior. The script should automatically do the following tasks to set up the environment: Install all required dependencies. Securely store your mnemonic as a docker secret Clone the Vector repo Once it's done, you should see a message that says Done configuring server, rebooting now.. Configuring the Router After setting up dependencies, ssh into the server and cd into the Vector repo: ssh -i ~/.ssh/{path}/{to}/{key} {username}@{server} cd vector As we mentioned on the Router Basics page, the router sits on top of a server-node and consumes its gRPC interface. This means that configuring a router is an extension of configuring a normal server-node ! Router Configuration Keys The router's node can be configured by adding any of the keys in config-node.json or config-router.json to config-prod.json (any values in config-prod.json will take precedence). The most important keys that you'll want to think about are: Key Type Description chainAddresses object Specifies the addresses of all relevant contracts, keyed by chainId . chainProviders object Specifies the URL to use to connect to each chain's provider, keyed by chainId logLevel string One of \"debug\" , \"info\" , \"warn\" , \"error\" to specify the maximum log level that will be printed. messagingUrl string The url used to connect to the messaging service. This will eventually be defaulted in prod-mode to a global service. port number The port number on which the stack should be exposed to the outside world. allowedSwaps object Specifies which swaps are allowed & how swap rates are determined. rebalanceProfiles object Specifies the thresholds & target while collateralizing some assetId on some chainId . awsAccessId string An API KEY id that specifies credentials for a remote AWS S3 bucket for storing db backups awsAccessKey string An API KEY secret that to authenticate on a remote AWS S3 bucket for storing db backups. domainName string If provided, https will be auto-configured & the stack will be exposed on port 443. production boolean Enables prod-mode if true. Implications: If false , ops will automatically build anything that isn't available locally before starting up a given stack. If false , the global stack will set up two testnet evms. If `true, nothing will be built locally. Info production=true and domainName are not yet fully supported. Setting Up Supported Chains To add support for one or many chains on this router, add a chainAddresses and chainProviders key to the config-prod.json file in the root of the vector repo: nano config-prod.json Recall that you deployed contracts to the chain(s) you want to support earlier in this guide . If you open up your address-book.json , you should find deployed addresses for your chain indexed by chainId . Copy them over into the config file like below. Also, plug in a providerURL into your chainProvider s object indexed at the same chainId. // Example Addresses \"chainAddresses\" : { \"4\" : { \"channelFactoryAddress\" : \"0xF12b5dd4EAD5F743C6BaA640B0216200e89B60Da\" , \"channelMastercopyAddress\" : \"0x8CdaF0CD259887258Bc13a92C0a6dA92698644C0\" , \"transferRegistryAddress\" : \"0x345cA3e014Aaf5dcA488057592ee47305D9B3e10\" , } } , \"chainProviders\" : { \"4\" : \"https://rinkeby.infura.io/abc123\" } , Tip You can support as many evm-compatible chains as you'd like in the above so long as they have a chainId and you have a provider for that chain! Setting Up Supported Assets Routers need to explicitly configure their supported assets. We do this by setting up a rebalanceProfile for each asset we want to support. In order to forward transfers, routers first need to have liquidity (i.e. collateral) in the recipient-side channel to route a transfer over. A rebalanceProfile defines parameters around minimum, maximum, and targete liquidity amounts for a given asset. We cover this in more depth in our Managing Collateral section. An example profile just for Eth looks like the following. Note that we use a combination of chainId and assetId to represent a given asset (where 0x0 is the \"base\" asset of the chain): // E.g. Eth { \"chainId\" : 1 , \"assetId\" : \"0x0000000000000000000000000000000000000000\" , \"reclaimThreshold\" : \"200000000000000000\" , \"target\" : \"100000000000000000\" , \"collateralizeThreshold\" : \"50000000000000000\" } , You can add profiles by setting them under the rebalanceProfile key in your config-prod.json : \"rebalanceProfiles\" : [ { \"chainId\" : 1 , \"assetId\" : \"0x0000000000000000000000000000000000000000\" , \"reclaimThreshold\" : \"200000000000000000\" , \"target\" : \"100000000000000000\" , \"collateralizeThreshold\" : \"50000000000000000\" }, { \"chainId\" : 1 , \"assetId\" : \"0x8f0483125FCb9aaAEFA9209D8E9d7b9C8B9Fb90F\" , \"reclaimThreshold\" : \"2000000000000000000\" , \"target\" : \"1000000000000000000\" , \"collateralizeThreshold\" : \"500000000000000000\" }, ] Connext routers also support in-flight swaps when forwarding transfers! In other words, a router can receive a transfer in $ETH and forward it in $DAI so long as an allowedSwap exists for that pair. To allow swapping between the two assets above, you can set the following up under the allowedSwaps key in your config-prod.json : \"allowedSwaps\" : [ { \"fromChainId\" : 1 , \"toChainId\" : 1 , \"fromAssetId\" : \"0x0000000000000000000000000000000000000000\" , \"toAssetId\" : \"0x8f0483125FCb9aaAEFA9209D8E9d7b9C8B9Fb90F\" , \"priceType\" : \"hardcoded\" , \"hardcodedRate\" : \"1\" }, { \"fromChainId\" : 1 , \"toChainId\" : 1 , \"fromAssetId\" : \"0x8f0483125FCb9aaAEFA9209D8E9d7b9C8B9Fb90F\" , \"toAssetId\" : \"0x0000000000000000000000000000000000000000\" , \"priceType\" : \"hardcoded\" , \"hardcodedRate\" : \"1\" } ] , Tip Above, we're setting default values for rebalance profiles and allowed swaps. In reality, these values (especially swap rates) likely need to be continuously updated at runtime every time period and/or on a per-channel basis. We go over how to plug in data sources for rates and profiles in our Managing Collateral section. Spinning Up the Router Now that we have our configuration complete, we can spin up the router! This part is pretty easy - in the root of the vector repo, do: make start-router The build process should take some time, but once it's done you should be able to GET the /config/ endpoint. Bug The above config endpoint doesn't yet work. We believe this is an issue with the proxy and are working to get it fixed ASAP.","title":"Configuration and Deployment"},{"location":"router/configure/#configuration-and-deployment","text":"This guide will take you through the e2e process of configuring and deploying a router. First get started by cloning the repo if you haven't already git clone git@github.com:connext/vector.git","title":"Configuration and Deployment"},{"location":"router/configure/#contract-deployment","text":"Before anything else, you should first ensure that the required Vector contracts are deployed to your chain. We have a global address-book in the root of the Vector repo which contains deployed contract addresses indexed by chainId. If you can't find the specific chain(s) that you want to set up a router at, you likely first need to deploy contracts. To deploy contracts, you can use our contracts CLI tool! First, build the repo: # in vector root make This should take a few moments. After it's done, cd into the contract repo and call the CLI migrate command: cd modules/contracts dist/cli.js migrate --address-book = /data/address-book.json --mnemonic = $mnemonic --ethProvider = $ethProvider Where $mnemonic controls a funded account on whatever chain you plan to deploy to, and $ethProvider is a provider URL for the same chain (e.g. Infura).","title":"Contract Deployment"},{"location":"router/configure/#setting-up-required-dependencies","text":"In this section, we assume that you are trying to deploy your router to a remote Ubuntu-based instance. If you're spinning up the router locally, or are using an instance on a different operating system, you'll need to install the following dependencies yourself: make : Probably already installed, otherwise install w brew install make or apt install make or similar. jq : Probably not installed yet, install w brew install jq or apt install jq or similar. docker : sadly, Docker is kinda annoying to install. See website for instructions. To set up dependencies for a remote Ubuntu-based instance, we will use the server-setup.sh script located in the ops/ dir. First, make sure that you've set up your instance and have the instance's IP/URL on hand + ssh access. Then, clone the repo locally if you haven't already: git clone git@github.com:connext/vector.git Info The prod configuration of the router will eventually include a built-in proxy that will automatically set up a DNS and SSL certificates for you. For now, we recommend directly connecting to an exposed instance without setting up a domain name until that's ready. Next, run bash ops/server-setup.sh passing in the instance's IP address or URL. The script will look for your AWS SSH key at -$HOME/.ssh/id_rsa . If your ssh key is located elsewhere, be sure to amend the server-setup.sh script to direct to your actual keyfile, or else it will fail to log in. When the script runs, it will prompt you to pass in a mnemonic. Generate a random mnemonic from here , copy it to your clipboard, and paste it into the prompt. If you choose not to enter a mnemonic, the router will use a default hardcoded mnemonic. Be sure to back up your mnemonic somewhere safe! Your mnemonic generates the primary key that controls the router. Warning We strongly recommend that you do not use the hardcoded mnemonic for any router that is connected to a public chain, including a testnet. The hardcoded mnemonic is publicly viewable in our repo and using it, even just for testing, could result in unpredictable behavior. The script should automatically do the following tasks to set up the environment: Install all required dependencies. Securely store your mnemonic as a docker secret Clone the Vector repo Once it's done, you should see a message that says Done configuring server, rebooting now..","title":"Setting Up Required Dependencies"},{"location":"router/configure/#configuring-the-router","text":"After setting up dependencies, ssh into the server and cd into the Vector repo: ssh -i ~/.ssh/{path}/{to}/{key} {username}@{server} cd vector As we mentioned on the Router Basics page, the router sits on top of a server-node and consumes its gRPC interface. This means that configuring a router is an extension of configuring a normal server-node !","title":"Configuring the Router"},{"location":"router/configure/#router-configuration-keys","text":"The router's node can be configured by adding any of the keys in config-node.json or config-router.json to config-prod.json (any values in config-prod.json will take precedence). The most important keys that you'll want to think about are: Key Type Description chainAddresses object Specifies the addresses of all relevant contracts, keyed by chainId . chainProviders object Specifies the URL to use to connect to each chain's provider, keyed by chainId logLevel string One of \"debug\" , \"info\" , \"warn\" , \"error\" to specify the maximum log level that will be printed. messagingUrl string The url used to connect to the messaging service. This will eventually be defaulted in prod-mode to a global service. port number The port number on which the stack should be exposed to the outside world. allowedSwaps object Specifies which swaps are allowed & how swap rates are determined. rebalanceProfiles object Specifies the thresholds & target while collateralizing some assetId on some chainId . awsAccessId string An API KEY id that specifies credentials for a remote AWS S3 bucket for storing db backups awsAccessKey string An API KEY secret that to authenticate on a remote AWS S3 bucket for storing db backups. domainName string If provided, https will be auto-configured & the stack will be exposed on port 443. production boolean Enables prod-mode if true. Implications: If false , ops will automatically build anything that isn't available locally before starting up a given stack. If false , the global stack will set up two testnet evms. If `true, nothing will be built locally. Info production=true and domainName are not yet fully supported.","title":"Router Configuration Keys"},{"location":"router/configure/#setting-up-supported-chains","text":"To add support for one or many chains on this router, add a chainAddresses and chainProviders key to the config-prod.json file in the root of the vector repo: nano config-prod.json Recall that you deployed contracts to the chain(s) you want to support earlier in this guide . If you open up your address-book.json , you should find deployed addresses for your chain indexed by chainId . Copy them over into the config file like below. Also, plug in a providerURL into your chainProvider s object indexed at the same chainId. // Example Addresses \"chainAddresses\" : { \"4\" : { \"channelFactoryAddress\" : \"0xF12b5dd4EAD5F743C6BaA640B0216200e89B60Da\" , \"channelMastercopyAddress\" : \"0x8CdaF0CD259887258Bc13a92C0a6dA92698644C0\" , \"transferRegistryAddress\" : \"0x345cA3e014Aaf5dcA488057592ee47305D9B3e10\" , } } , \"chainProviders\" : { \"4\" : \"https://rinkeby.infura.io/abc123\" } , Tip You can support as many evm-compatible chains as you'd like in the above so long as they have a chainId and you have a provider for that chain!","title":"Setting Up Supported Chains"},{"location":"router/configure/#setting-up-supported-assets","text":"Routers need to explicitly configure their supported assets. We do this by setting up a rebalanceProfile for each asset we want to support. In order to forward transfers, routers first need to have liquidity (i.e. collateral) in the recipient-side channel to route a transfer over. A rebalanceProfile defines parameters around minimum, maximum, and targete liquidity amounts for a given asset. We cover this in more depth in our Managing Collateral section. An example profile just for Eth looks like the following. Note that we use a combination of chainId and assetId to represent a given asset (where 0x0 is the \"base\" asset of the chain): // E.g. Eth { \"chainId\" : 1 , \"assetId\" : \"0x0000000000000000000000000000000000000000\" , \"reclaimThreshold\" : \"200000000000000000\" , \"target\" : \"100000000000000000\" , \"collateralizeThreshold\" : \"50000000000000000\" } , You can add profiles by setting them under the rebalanceProfile key in your config-prod.json : \"rebalanceProfiles\" : [ { \"chainId\" : 1 , \"assetId\" : \"0x0000000000000000000000000000000000000000\" , \"reclaimThreshold\" : \"200000000000000000\" , \"target\" : \"100000000000000000\" , \"collateralizeThreshold\" : \"50000000000000000\" }, { \"chainId\" : 1 , \"assetId\" : \"0x8f0483125FCb9aaAEFA9209D8E9d7b9C8B9Fb90F\" , \"reclaimThreshold\" : \"2000000000000000000\" , \"target\" : \"1000000000000000000\" , \"collateralizeThreshold\" : \"500000000000000000\" }, ] Connext routers also support in-flight swaps when forwarding transfers! In other words, a router can receive a transfer in $ETH and forward it in $DAI so long as an allowedSwap exists for that pair. To allow swapping between the two assets above, you can set the following up under the allowedSwaps key in your config-prod.json : \"allowedSwaps\" : [ { \"fromChainId\" : 1 , \"toChainId\" : 1 , \"fromAssetId\" : \"0x0000000000000000000000000000000000000000\" , \"toAssetId\" : \"0x8f0483125FCb9aaAEFA9209D8E9d7b9C8B9Fb90F\" , \"priceType\" : \"hardcoded\" , \"hardcodedRate\" : \"1\" }, { \"fromChainId\" : 1 , \"toChainId\" : 1 , \"fromAssetId\" : \"0x8f0483125FCb9aaAEFA9209D8E9d7b9C8B9Fb90F\" , \"toAssetId\" : \"0x0000000000000000000000000000000000000000\" , \"priceType\" : \"hardcoded\" , \"hardcodedRate\" : \"1\" } ] , Tip Above, we're setting default values for rebalance profiles and allowed swaps. In reality, these values (especially swap rates) likely need to be continuously updated at runtime every time period and/or on a per-channel basis. We go over how to plug in data sources for rates and profiles in our Managing Collateral section.","title":"Setting Up Supported Assets"},{"location":"router/configure/#spinning-up-the-router","text":"Now that we have our configuration complete, we can spin up the router! This part is pretty easy - in the root of the vector repo, do: make start-router The build process should take some time, but once it's done you should be able to GET the /config/ endpoint. Bug The above config endpoint doesn't yet work. We believe this is an issue with the proxy and are working to get it fixed ASAP.","title":"Spinning Up the Router"}]}